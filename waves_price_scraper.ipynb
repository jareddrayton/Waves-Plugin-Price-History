{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "The company Waves produces plugins for use in audio production. To remain competitive in an increasingly saturated market it has transitioned to a pricing model where discounts are offered year round, however, the amount of discount applied to each product varies throught out the year by quite a considerable margin. It would be beneficial to have the ability to see how a current sale price compares historically in order to know if it is an optimum time to buy.\n",
    "\n",
    "The objective is to write a scraper to perodically retrieve pricing for each item of both regular pricing, and the sale price. Similar to how camel camel camel tracks prices on Amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Target Page\n",
    "\n",
    "The main products page is found at the following URL https://www.waves.com/plugins, however, after visiting this URL, a URL fragment is automatically added by the site taking the following form\n",
    "\n",
    "https://www.waves.com/plugins#sort:path~type~order=.hidden-price~number~asc|views:view=grid-view|paging:currentPage=0|paging:number=20\n",
    "\n",
    "By default 20 items are displayed, with the need to cycle through multiple pages to see futher items. However, by changing the number \"20\" to \"all\" in the URL fragment, it will display all availiable products on one page. This obviously bypasses the need to introduce any functionality to drive the website. \n",
    "\n",
    "Also, by scanning the list of products we can see that at the very bottom, certain items do not have a regular price or sale price and are only availiable through the purchase of particular bundles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Download the HTML page using requests\n",
    "url = 'https://www.waves.com/plugins#sort:path~type~order=.hidden-price~number~asc|views:view=grid-view|paging:currentPage=0|paging:number=all'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "with open('Waves_plugins.html', 'wb') as webpage:\n",
    "    webpage.write(r.content)  \n",
    "\n",
    "# Open the manually downloaded webpage and create a new BeautifulSoup object\n",
    "with open('Waves_plugins.html', encoding='utf8') as html_file:\n",
    "    soup = BeautifulSoup(html_file, 'lxml')\n",
    "\n",
    "# Remove the HTML file\n",
    "os.remove(\"Waves_plugins.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting the HTML file manually, it looks like data for each product is contained within `<article>` tags.\n",
    "Using `find_all` with the article tag and calling len() on this object shows that there are 203 items with the `<article>` tag, which is the same number of products listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    }
   ],
   "source": [
    "print(len(soup.find_all('article')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           date       product_id  \\\n",
      "0    2019-11-12 23:35:10.079830    node-ABRDTGMC   \n",
      "1    2019-11-12 23:35:10.081828  node-API2500TDM   \n",
      "2    2019-11-12 23:35:10.083826     node-BSSLAPP   \n",
      "3    2019-11-12 23:35:10.085824     node-BRERMOT   \n",
      "4    2019-11-12 23:35:10.089820      node-BSSDPR   \n",
      "..                          ...              ...   \n",
      "810  2019-11-13 12:09:08.458154     node-S360TDM   \n",
      "811  2019-11-13 12:09:08.460151      node-DTSNDM   \n",
      "812  2019-11-13 12:09:08.462147      node-DTSNUM   \n",
      "813  2019-11-13 12:09:08.465145     node-DTSNMST   \n",
      "814  2019-11-13 12:09:08.467143      node-DDSPCH   \n",
      "\n",
      "                      product_title regular_price sale_price  \n",
      "0     Abbey Road TG Mastering Chain           199      29.99  \n",
      "1                          API 2500           299      29.99  \n",
      "2                      Bass Slapper            69      29.99  \n",
      "3                     Brauer Motion            99      29.99  \n",
      "4                       BSS DPR-402           149      29.99  \n",
      "..                              ...           ...        ...  \n",
      "810   S360 Surround Imager & Panner           NaN        NaN  \n",
      "811  DTS Neuralâ¢ Surround DownMix           NaN        NaN  \n",
      "812    DTS Neuralâ¢ Surround UpMix           NaN        NaN  \n",
      "813       DTS Neuralâ¢ Mono2Stereo           NaN        NaN  \n",
      "814                    Dugan Speech           NaN        NaN  \n",
      "\n",
      "[815 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('waves_price_history.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"date\", \"product_id\", \"product_title\", \"regular_price\", \"sale_price\"])\n",
    "\n",
    "# Loop over  \n",
    "for product in soup.find_all('article'):\n",
    "    \n",
    "    product_id = product['id']\n",
    "    product_title = product.find('p', class_='title').get_text(strip=True)\n",
    "    \n",
    "    regular_price = product.find('div', class_='regular-price align-center')\n",
    "\n",
    "    if regular_price != None:\n",
    "        regular_price = regular_price.get_text(strip=True).strip()\n",
    "        regular_price = [s for s in regular_price if s.isnumeric() == True]\n",
    "        regular_price = \"\".join(regular_price)\n",
    "        regular_price = regular_price + \".00\"\n",
    "    \n",
    "    sale_price = product.find('div', class_='on-sale-price align-center')\n",
    "    \n",
    "    if sale_price != None:\n",
    "        sale_price = sale_price.get_text(strip=True).strip()\n",
    "        sale_price = [s for s in sale_price if s.isnumeric() == True]\n",
    "        sale_price = \"\".join(sale_price)\n",
    "        sale_price = sale_price[:-2] + \".99\"\n",
    "    \n",
    "    # print(product_id, product_title, regular_price, sale_price)    \n",
    "    \n",
    "    with open('waves_price_history.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_ALL)\n",
    "        spamwriter.writerow([datetime.now(), product_id, product_title, regular_price, sale_price])\n",
    "\n",
    "price_history = pd.read_csv(\"waves_price_history.csv\", encoding = \"ISO-8859-1\", sep=\" \", quotechar='|')        \n",
    "print(price_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "1. Move code into a seperate .py file then set up as a cron job or another method that runs it periodically.\n",
    "2. Create some kind of web frontend way to access the data contained in the csv in a useful way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Issues and Bugs\n",
    "\n",
    "1. For products which cost more than 99.99 they have whole number dollar amounts. This breaks the price formatting.\n",
    "2. When updating the csv file, it would be more efficient to only add new data when there has been a price change.\n",
    "3. Seems to be some Unicode issues with the TradeMark sign used in the \"Neural\" named products. Temporary work around is to use `encoding = \"ISO-8859-1\"` when opening with pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
